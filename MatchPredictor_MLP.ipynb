{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MatchPredictor_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Is0DNAr7W2sc",
        "A3RvsJpwW2sc",
        "m_1ZIfpIW2sc",
        "ErVMQAJVfGi6"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4WnfXTuW2sb"
      },
      "source": [
        "# MatchPredictor\n",
        "\n",
        "### A neural network which predicts the outcomes of Premier League football matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4uLPYGzW2sb"
      },
      "source": [
        "#### Importing Libraries & Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3D867YUW2sb",
        "outputId": "b738370c-0df8-466f-d545-72cba1da9c1d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Microsoft Visual C++ Redistributable is not installed, this may lead to the DLL load failure.\n",
            "                 It can be downloaded at https://aka.ms/vs/16/release/vc_redist.x64.exe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukm7le4QW2sc"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k1mUJUiW2sc"
      },
      "source": [
        "past = 5    # How many past games are taken into account for team form calculations\n",
        "rseed = 1 \n",
        "num_epoch = 100\n",
        "fc1_size = 32\n",
        "fc2_size = 32\n",
        "fc3_size = 20\n",
        "out_size = 3\n",
        "            #add num hidden layers, optimizer loss fcn\n",
        "lr = 0.01 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is0DNAr7W2sc"
      },
      "source": [
        "#### Importing Match Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC0-M0RiW2sc"
      },
      "source": [
        "# Imported CSV becomes a pandas dataframe object\n",
        "data_20 = pd.read_csv(\"Prem_data_19-20\\england-premier-league-matches-2019-to-2020-stats.csv\")\n",
        "data_19 = pd.read_csv(\"Prem_data_18-19\\england-premier-league-matches-2018-to-2019-stats.csv\")\n",
        "data_18 = pd.read_csv(\"Prem_data_17-18\\england-premier-league-matches-2017-to-2018-stats.csv\")\n",
        "data_17 = pd.read_csv(\"Prem_data_16-17\\england-premier-league-matches-2016-to-2017-stats.csv\")\n",
        "data_16 = pd.read_csv(\"Prem_data_15-16\\england-premier-league-matches-2015-to-2016-stats.csv\")\n",
        "data_15 = pd.read_csv(\"Prem_data_14-15\\england-premier-league-matches-2014-to-2015-stats.csv\")\n",
        "data_14 = pd.read_csv(\"Prem_data_13-14\\england-premier-league-matches-2013-to-2014-stats.csv\")\n",
        "data_13 = pd.read_csv(\"Prem_data_12-13\\england-premier-league-matches-2012-to-2013-stats.csv\")\n",
        "\n",
        "\n",
        "data = [data_20, data_19, data_18, data_17, data_16, data_15, data_14, data_13]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_1ZIfpIW2sc"
      },
      "source": [
        "#### DATA PREPROCSESSING  \n",
        "  \n",
        "Here we create the inputs for our model from the raw .csv files we collected from *footystats.org*.  \n",
        "  \n",
        "- Each season will be represented by a matrix.  \n",
        "- Each row of this matrix will consist of the inputs that describe a single match to the neural net.  \n",
        "  \n",
        "In each row, the entries are as follows:  \n",
        "*Note: **past** is an integer hyperparameter*  \n",
        "  \n",
        "**Index 0**: Home team average goals scored per game over last **past** games.  \n",
        "**Index 1**:  Home team average goals conceded per game over last **past** games.  \n",
        "**Index 2**:  Home team pre-match PPG.  \n",
        "**Index 3**:  Home team ppg from last game (so current game isn’t included).  \n",
        "**Index 4**:  Home team average number of shots on target over last **past** games.  \n",
        "**Index 5**:  Home team average number of corners over last **past** games.  \n",
        "**Index 6**:  Away team average goals scored per game over last **past** games.  \n",
        "**Index 7**:  Away team average goals conceded per game over last **past** games.  \n",
        "**Index 8**:  Away team pre-match PPG.  \n",
        "**Index 9**:  Away team ppg from last game (so current game isn’t included).  \n",
        "**Index 10**:  Away team average number of shots on target over last **past** games.  \n",
        "**Index 11**:  Away team average number of corners over last **past** games.  \n",
        "**Index 12 (LABEL)**:  0 if Home Team won, 1 if Away Team won, 2 if Draw. \n",
        "  \n",
        "  \n",
        "*NOTE: The first \"past\" weeks from each season cannot be used in training/testing as they have no previous matches to get data from.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amz4WMIWW2sc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "c5a8f886-50a4-4c69-acb9-09f955ba8443"
      },
      "source": [
        "# Set up empty matrices to be filled with INPUTS.\n",
        "# Once filled with values, each row will represent the inputs that describe a match to the NN.\n",
        "    \n",
        "in_20 = np.zeros((380-(past*10),13))\n",
        "in_19 = np.zeros((380-(past*10),13))\n",
        "in_18 = np.zeros((380-(past*10),13))\n",
        "in_17 = np.zeros((380-(past*10),13))\n",
        "in_16 = np.zeros((380-(past*10),13))\n",
        "in_15 = np.zeros((380-(past*10),13))\n",
        "in_14 = np.zeros((380-(past*10),13))\n",
        "in_13 = np.zeros((380-(past*10),13))\n",
        "\n",
        "\n",
        "input_seasons = [in_20, in_19, in_18, in_17, in_16, in_15, in_14, in_13]\n",
        "\n",
        "\n",
        "season_idx = 0\n",
        "for season in data:\n",
        "    \n",
        "    week = past + 1\n",
        "    input_season = input_seasons[season_idx]\n",
        "    \n",
        "    \n",
        "    while week < 39:\n",
        "        \n",
        "        row_idx = (week-1)*10             # index of the first match of new week\n",
        "        match_count = 0                   # counting the 10 matches played in a given week\n",
        "\n",
        "        \n",
        "        while match_count < 10:\n",
        "            \n",
        "            match = season.iloc[[row_idx]]                     # saving current match\n",
        "            \n",
        "             # getting match LABEL (match result)\n",
        "            if (match.iat[0,12] > match.iat[0,13]):            \n",
        "                    result = 0   # home team win\n",
        "            elif (match.iat[0,12] < match.iat[0,13]):\n",
        "                    result = 1   # away team win\n",
        "            else:\n",
        "                    result = 2   # draw\n",
        "                    \n",
        "            \n",
        "            home_team = season.at[row_idx,'home_team_name']    # saving home team name\n",
        "            away_team = season.at[row_idx,'away_team_name']    # saving away team name\n",
        "            \n",
        "            total_home_goals = 0                               # counts total goals scored by home team over \"past\" matches\n",
        "            total_away_goals = 0                               # counts total goals scored by away team over \"past\" matches\n",
        "            \n",
        "            total_home_conceded = 0                            # counts total goals scored against home team over \"past\" matches \n",
        "            total_away_conceded = 0                            # counts total goals scored against away team over \"past\" matches\n",
        "            \n",
        "            total_home_shotson = 0                             # counts total shots on target taken by home team over...\n",
        "            total_away_shotson = 0                             # counts total shots on target taken by away team over...\n",
        "            \n",
        "            total_home_corners = 0                             # counts total corners taken by home team over...\n",
        "            total_away_corners = 0                             # counts total corners taken by away team over...\n",
        "            \n",
        "            home_PPG_pre = match.iat[0,8]                      # home team pre-match points per game (PPG)\n",
        "            away_PPG_pre = match.iat[0,9]                      # away team pre-match points per game (PPG)\n",
        "            \n",
        "            \n",
        "            previous = 1                                       # counts up to \"past\"\n",
        "            \n",
        "            \n",
        "            while previous <= past:\n",
        "\n",
        "                home_match_prev = season.loc[(season['home_team_name'] == home_team) & (season['Game Week'] == week-previous)]   # picking out home team's previous match\n",
        "                h_sc_idx = 12       # home team score index\n",
        "                h_shon_idx = 32     # home shots on target index\n",
        "                h_corn_idx = 20     # home corners index\n",
        "                h_ppg_idx = 10\n",
        "                \n",
        "                away_match_prev = season.loc[(season['away_team_name'] == away_team) & (season['Game Week'] == week-previous)]   # picking out away team's previous match\n",
        "                a_sc_idx = 13       # away team score index\n",
        "                a_shon_idx = 33     # away team shots on target index\n",
        "                a_corn_idx = 21     # away corners index\n",
        "                a_ppg_idx = 11\n",
        "                \n",
        "                # if home team name was not found in 'home_team_name' column...\n",
        "                if (home_match_prev.size == 0):\n",
        "                    home_match_prev = season.loc[(season['away_team_name'] == home_team) & (season['Game Week'] == week-previous)]   # picking out home team's previous match\n",
        "                    h_sc_idx = 13      # home team score index\n",
        "                    h_shon_idx = 33    # home shots on target index\n",
        "                    h_corn_idx = 21    # home corners index\n",
        "                    h_ppg_idx = 11\n",
        "                    \n",
        "                # if away team name was not found in 'away_team_name' column...\n",
        "                if (away_match_prev.size == 0):\n",
        "                    away_match_prev = season.loc[(season['home_team_name'] == away_team) & (season['Game Week'] == week-previous)]   # picking out away team's previous match\n",
        "                    a_sc_idx = 12      # away team score index\n",
        "                    a_shon_idx = 32    # away team shots on target index\n",
        "                    a_corn_idx = 20    # away corners index\n",
        "                    a_ppg_idx = 10\n",
        "                    \n",
        "                # if loop is 1 match in the past...   \n",
        "                if previous == 1:\n",
        "                    home_PPG = home_match_prev.iat[0,h_ppg_idx]\n",
        "                    away_PPG = away_match_prev.iat[0,a_ppg_idx]\n",
        "                    \n",
        "                #print(home_team, 'goals scored in week', week-previous, '= ', home_match_prev.iat[0,h_sc_idx])\n",
        "                total_home_goals += home_match_prev.iat[0,h_sc_idx]\n",
        "                total_away_goals += away_match_prev.iat[0,a_sc_idx]\n",
        "                \n",
        "                #print(home_team, 'goals conceded in week', week-previous, '=', home_match_prev.iat[0,a_sc_idx])\n",
        "                total_home_conceded += home_match_prev.iat[0,a_sc_idx]\n",
        "                total_away_conceded += away_match_prev.iat[0,h_sc_idx]\n",
        "                \n",
        "                total_home_shotson += home_match_prev.iat[0,h_shon_idx]\n",
        "                total_away_shotson += away_match_prev.iat[0,a_shon_idx]\n",
        "                \n",
        "                total_home_corners += home_match_prev.iat[0,h_corn_idx]\n",
        "                total_away_corners += away_match_prev.iat[0,a_corn_idx]\n",
        "                \n",
        "                \n",
        "                previous += 1\n",
        "\n",
        "            in_idx = row_idx - (past*10)\n",
        "            input_season[in_idx][0] = total_home_goals/past          # input INDEX 0 (home team avg. goals over \"past\")\n",
        "            input_season[in_idx][1] = total_home_conceded/past       # input INDEX 1 (home team avg. conceded goals over \"past\")\n",
        "            input_season[in_idx][2] = home_PPG_pre                   # input INDEX 2 (home team pre-match PPG: PPG in current season)\n",
        "            input_season[in_idx][3] = home_PPG                       # input INDEX 3 (home team PPG including past seasons)\n",
        "            input_season[in_idx][4] = total_home_shotson/past        # input INDEX 4 (home team avg. shots on target over \"past\")\n",
        "            input_season[in_idx][5] = total_home_corners/past        # input INDEX 5 (home team avg. corner kicks over \"past\")\n",
        "            input_season[in_idx][6] = total_away_goals/past          # input INDEX 6 (away team avg. goals over \"past\")\n",
        "            input_season[in_idx][7] = total_away_conceded/past       # input INDEX 7 (away team avg. conceded goals over \"past\")\n",
        "            input_season[in_idx][8] = away_PPG_pre                   # input INDEX 8 (away team pre-match PPG: PPG in current season)\n",
        "            input_season[in_idx][9] = away_PPG                       # input INDEX 9 (away team PPG including past seasons)\n",
        "            input_season[in_idx][10] = total_away_shotson/past       # input INDEX 10 (away team avg. shots on target over \"past\")\n",
        "            input_season[in_idx][11] = total_away_corners/past       # input INDEX 11 (away team avg. corner kicks over \"past\")\n",
        "            input_season[in_idx][12] = result                        # label INDEX 12 (match result)\n",
        "            \n",
        "            #print(input_season[in_idx])\n",
        "            \n",
        "            row_idx += 1\n",
        "            match_count += 1\n",
        "\n",
        "        week += 1\n",
        "        \n",
        "    season_idx += 1\n",
        "      \n",
        "        \n",
        "print('19/20 season input matrix: \\n', in_20, '\\n')\n",
        "print('18/19 season input matrix: \\n', in_19, '\\n')\n",
        "print('17/18 season input matrix: \\n', in_18, '\\n')\n",
        "print('16/17 season input matrix: \\n', in_17, '\\n')\n",
        "print('15/16 season input matrix: \\n', in_16, '\\n')\n",
        "print('14/15 season input matrix: \\n', in_15, '\\n')\n",
        "print('13/14 season input matrix: \\n', in_14, '\\n')\n",
        "print('12/13 season input matrix: \\n', in_13, '\\n')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e85d0fc1fa27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Once filled with values, each row will represent the inputs that describe a match to the NN.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0min_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m380\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0min_19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m380\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0min_18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m380\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_QroHKoW2sd"
      },
      "source": [
        "## Multi-Layer Perceptron Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEdgVrZRW2sd"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "class MultiLayerPerceptron(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size,h_sizes,act):\n",
        "      #current parameters are:\n",
        "        #input size = matrix size\n",
        "        #h_sizes = list of each layer size ->ex: [64,64,64,64,3]\n",
        "        #MAKE SURE LAST HID_LAYER OUTPUTS TO 3\n",
        "        #act_fcn = ?\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "        self.hidden = nn.ModuleList()\n",
        "        for k in range(len(h_sizes)-2):\n",
        "            self.hidden.append(nn.Linear(h_sizes[k], h_sizes[k+1]))\n",
        "\n",
        "        if act =='relu':\n",
        "          self.act = F.relu()\n",
        "        elif act == 'sigmoid':  \n",
        "          self.act = F.sigmoid()\n",
        "        self.out = F.softmax()\n",
        "\n",
        "\n",
        "        # self.fc1 = nn.Linear(input_size,64)\n",
        "        # self.fc2 = nn.Linear(64,64)\n",
        "        # self.fc3 = nn.Linear(64,64)\n",
        "        # self.fc4 = nn.Linear(64,3)   #output is 3 classes for home win, away win, tie\n",
        "\n",
        "    def forward(self, x):\n",
        "      for i in self.hidden:\n",
        "        x = self.act(self.hidden[i])\n",
        "      x =  self.out(x)\n",
        "\n",
        "        # x = F.relu(self.fc1(x))\n",
        "        # x = F.relu(self.fc2(x))\n",
        "        # x = F.relu(self.fc3(x))\n",
        "        # x = F.relu(self.fc4(x))\n",
        "        # x = torch.sigmoid(x)\n",
        "    return x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK461FjGZrXc"
      },
      "source": [
        "###Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M0Mu74T_7V0"
      },
      "source": [
        "#### Get prediction from output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnXEA5wlAAUu"
      },
      "source": [
        "def get_preds(z):\n",
        "  dims = z.size()\n",
        "  out = np.zeros(dims)\n",
        "  #inputs: output of model\n",
        "  #outputs: corresponding output to prediction\n",
        "  max_idxs = torch.max(z,1)[1]\n",
        "  print(max_idxs)\n",
        "  for entry,idx in enumerate(max_idxs,0):\n",
        "      for val in range(dims[1]):\n",
        "        if val == idx:\n",
        "          out[entry][val] = 1\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErVMQAJVfGi6"
      },
      "source": [
        "####accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GGnhmzFZzpc"
      },
      "source": [
        "def accuracy(preds, labels):\n",
        "    #inputs: preds: array, labels:array \n",
        "    #output: overall accuracy\n",
        "    correct = 0\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i] == labels[i]:\n",
        "          correct +=1\n",
        "    return (correct/len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJlCum_EBNLh"
      },
      "source": [
        "####validate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8PwjiNodBWz"
      },
      "source": [
        "def validate(model,val_loader,loss_fcn):\n",
        "  val_acc=[]\n",
        "  val_loss=[]\n",
        "  for epoch in range(0,num_epochs):\n",
        "    for i,data in enumerate(val_loader,0): #iterate over val_loader, start idx=0\n",
        "      inputs,labels = data  #val_loader idx0->data, idx1->labels\n",
        "      \n",
        "      labels = F.one_hot(labels) #convert labels 0:home 1:away 2:tie to vector. Ex: 0->[1,0,0] 1->[0,1,0], 2->[0,0,1]\n",
        "\n",
        "      optimizer.zero_grad()  #initialize the gradients to zero  \n",
        "\n",
        "      z = model(inputs)\n",
        "      \n",
        "      preds = get_preds(z) #preds used for accuracy \n",
        "      loss = loss_fcn(input=z.squeeze(), target=labels.float())\n",
        "\n",
        "      mini_val_acc.append(accuracy(preds,labels))\n",
        "      mini_val_loss.append(loss.item())\n",
        "\n",
        "  ValLoss = sum(val_loss)/len(val_loss)\n",
        "  ValAcc = sum(val_acc) / len(val_acc)\n",
        "  \n",
        "  return ValAcc, ValLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbQCrISXWN46"
      },
      "source": [
        "#### plotting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd9apCNOWOHQ"
      },
      "source": [
        "def plot(epoch, train_var, val_var,xlabel,ylabel):\n",
        "    plt.plot(epoch, train_var, label = 'train')\n",
        "    plt.plot(epoch, val_var, label = 'validation')\n",
        "    plt.title(str(xlabel) + ' vs. '+str(ylabel))\n",
        "    plt.xlabel(str(xlabel))\n",
        "    plt.ylabel(str(ylabel))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kAaa_MEjVrw"
      },
      "source": [
        "#### MLP loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3vF0n-IjUwj"
      },
      "source": [
        "def load_MLP(lr):\n",
        "  #add optimizer,loss functions as a hyperparameters\n",
        "  model = MultiLayerPerceptron(input_size)\n",
        "  optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
        "  loss_fcn = nn.MSELoss()\n",
        "  return model,optimizer,loss_fcn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfaT7X6ZiWn_"
      },
      "source": [
        "##Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18YWlXsYim9y"
      },
      "source": [
        "def train(rseed,lr,num_epochs):\n",
        "\n",
        "  torch.manual_seed(rseed)\n",
        "\n",
        "  model,optimizer,loss_fcn = load_MLP(lr)   #initialize model \n",
        "  soft = nn.SoftMax(dim=1) #create softmax act function\n",
        "\n",
        "\n",
        "  #records for plotting \n",
        "  TrainAccRec = []\n",
        "  TrainLossRec = []\n",
        "  ValAccRec = []  \n",
        "  ValLossRec = []\n",
        " \n",
        "# ========================================TRAINING LOOP =========================================# \n",
        "  for epoch in range(0,num_epochs):\n",
        "    for i,data in enumerate(train_loader,0): #iterate over train_loader, start idx=0\n",
        "      inputs,labels = data  #trainloader idx0->data, idx1->labels\n",
        "      \n",
        "      labels = F.one_hot(labels) #convert labels 0:home 1:away 2:tie to vector. Ex: 0->[1,0,0] 1->[0,1,0], 2->[0,0,1]\n",
        "\n",
        "      optimizer.zero_grad()  #initialize the gradients to zero  \n",
        "\n",
        "      z = model(inputs)  #z array of vector outputs, each size=3 \n",
        "\n",
        "      #z = soft(z)  #may not need since using sigmoid act fcn already\n",
        "\n",
        "      preds = get_preds(z) #preds used for accuracy \n",
        "\n",
        "      loss = loss_fcn(input=z.squeeze(), target=labels.float())\n",
        "\n",
        "      \n",
        "      loss.backward() #get gradients \n",
        "     \n",
        "      optimizer.step() #update parameters\n",
        "\n",
        "      train_acc = accuracy(preds,labels)\n",
        "      train_loss = loss.item()\n",
        "\n",
        "      val_acc, val_loss = validate(model, val_loader,loss_fcn)\n",
        "        \n",
        "    #add to overall records\n",
        "      TrainAccRec.append(train_acc)\n",
        "      TrainLossRec.append(train_loss)\n",
        "      ValAccRec.append(epoch_val_acc)\n",
        "      ValLossRec.append(epoch_val_loss)\n",
        "\n",
        "    # print(\"Epoch:\",epoch+1)\n",
        "    # print(\"train acc:\",epoch_train_acc)\n",
        "    # print(\"val acc:\",epoch_val_acc)\n",
        " \n",
        "    \n",
        "\n",
        "#plottting\n",
        "  e = np.arange(0,num_epochs)\n",
        "  plot(e,TrainAccRec,ValAccRec,'Epochs','Accuracy')\n",
        "  plot(e,TrainLossRec,ValLossRec,'Epochs','Losses')\n",
        "  print(\"Max training accuracy\",max(TrainAccRec))\n",
        "  print(\"Max Validation accuracy\",max(ValAccRec))\n",
        "  print(\"Min training loss\",min(TrainLossRec))\n",
        "  print(\"Min Validation loss\",min(ValLossRec))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}