{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4WnfXTuW2sb"
   },
   "source": [
    "# MatchPredictor\n",
    "\n",
    "### A neural network which predicts the outcomes of Premier League football matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4uLPYGzW2sb"
   },
   "source": [
    "#### Importing Libraries & Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "L3D867YUW2sb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukm7le4QW2sc"
   },
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1k1mUJUiW2sc"
   },
   "outputs": [],
   "source": [
    "past = 5    # How many past games are taken into account for team form calculations\n",
    "rseed = 1 \n",
    "num_epoch = 100\n",
    "fc1_size = 32\n",
    "fc2_size = 32\n",
    "fc3_size = 20\n",
    "out_size = 3\n",
    "            #add num hidden layers, optimizer loss fcn\n",
    "lr = 0.01 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is0DNAr7W2sc"
   },
   "source": [
    "#### Importing Match Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fC0-M0RiW2sc"
   },
   "outputs": [],
   "source": [
    "# Imported CSV becomes a pandas dataframe object\n",
    "data_20 = pd.read_csv(\"Prem_data_19-20\\england-premier-league-matches-2019-to-2020-stats.csv\")\n",
    "data_19 = pd.read_csv(\"Prem_data_18-19\\england-premier-league-matches-2018-to-2019-stats.csv\")\n",
    "data_18 = pd.read_csv(\"Prem_data_17-18\\england-premier-league-matches-2017-to-2018-stats.csv\")\n",
    "data_17 = pd.read_csv(\"Prem_data_16-17\\england-premier-league-matches-2016-to-2017-stats.csv\")\n",
    "data_16 = pd.read_csv(\"Prem_data_15-16\\england-premier-league-matches-2015-to-2016-stats.csv\")\n",
    "data_15 = pd.read_csv(\"Prem_data_14-15\\england-premier-league-matches-2014-to-2015-stats.csv\")\n",
    "data_14 = pd.read_csv(\"Prem_data_13-14\\england-premier-league-matches-2013-to-2014-stats.csv\")\n",
    "data_13 = pd.read_csv(\"Prem_data_12-13\\england-premier-league-matches-2012-to-2013-stats.csv\")\n",
    "\n",
    "\n",
    "data = [data_20, data_19, data_18, data_17, data_16, data_15, data_14, data_13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_1ZIfpIW2sc"
   },
   "source": [
    "#### DATA PREPROCSESSING  \n",
    "  \n",
    "Here we create the inputs for our model from the raw .csv files we collected from *footystats.org*.  \n",
    "  \n",
    "- Each season will be represented by a matrix.  \n",
    "- Each row of this matrix will consist of the inputs that describe a single match to the neural net.  \n",
    "  \n",
    "In each row, the entries are as follows:  \n",
    "*Note: **past** is an integer hyperparameter*  \n",
    "  \n",
    "**Index 0**: Home team average goals scored per game over last **past** games.  \n",
    "**Index 1**:  Home team average goals conceded per game over last **past** games.  \n",
    "**Index 2**:  Home team pre-match PPG (over current season).  \n",
    "**Index 3**:  Home team ppg from last game, so current game isn't included (calculated over multiple seasons).  \n",
    "**Index 4**:  Home team average number of shots on target over last **past** games.  \n",
    "**Index 5**:  Home team average number of corners over last **past** games.  \n",
    "**Index 6**:  Away team average goals scored per game over last **past** games.  \n",
    "**Index 7**:  Away team average goals conceded per game over last **past** games.  \n",
    "**Index 8**:  Away team pre-match PPG (over current season).  \n",
    "**Index 9**:  Away team ppg from last game, so current game isn't included (calculated over multiple seasons).  \n",
    "**Index 10**:  Away team average number of shots on target over last **past** games.  \n",
    "**Index 11**:  Away team average number of corners over last **past** games.  \n",
    "**Index 12 (LABEL)**:  0 if Home Team won, 1 if Away Team won, 2 if Draw. \n",
    "  \n",
    "  \n",
    "*NOTE: The first \"past\" weeks from each season cannot be used in training/testing as they have no previous matches to get data from.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Amz4WMIWW2sc",
    "outputId": "e68782e8-7503-4db5-9152-94df01af2299"
   },
   "outputs": [],
   "source": [
    "# Set up empty matrices to be filled with INPUTS.\n",
    "# Once filled with values, each row will represent the inputs that describe a match to the NN.\n",
    "    \n",
    "in_20 = np.zeros((380-(past*10),13))\n",
    "in_19 = np.zeros((380-(past*10),13))\n",
    "in_18 = np.zeros((380-(past*10),13))\n",
    "in_17 = np.zeros((380-(past*10),13))\n",
    "in_16 = np.zeros((380-(past*10),13))\n",
    "in_15 = np.zeros((380-(past*10),13))\n",
    "in_14 = np.zeros((380-(past*10),13))\n",
    "in_13 = np.zeros((380-(past*10),13))\n",
    "\n",
    "\n",
    "\n",
    "input_seasons = [in_20, in_19, in_18, in_17, in_16, in_15, in_14, in_13]\n",
    "\n",
    "\n",
    "season_idx = 0\n",
    "for season in data:\n",
    "    \n",
    "    week = past + 1\n",
    "    input_season = input_seasons[season_idx]\n",
    "    \n",
    "    \n",
    "    while week < 39:\n",
    "        \n",
    "        row_idx = (week-1)*10             # index of the first match of new week\n",
    "        match_count = 0                   # counting the 10 matches played in a given week\n",
    "\n",
    "        \n",
    "        while match_count < 10:\n",
    "            \n",
    "            match = season.iloc[[row_idx]]                     # saving current match\n",
    "            \n",
    "             # getting match LABEL (match result)\n",
    "            if (match.iat[0,12] > match.iat[0,13]):            \n",
    "                    result = 0   # home team win\n",
    "            elif (match.iat[0,12] < match.iat[0,13]):\n",
    "                    result = 1   # away team win\n",
    "            else:\n",
    "                    result = 2   # draw\n",
    "                    \n",
    "            \n",
    "            home_team = season.at[row_idx,'home_team_name']    # saving home team name\n",
    "            away_team = season.at[row_idx,'away_team_name']    # saving away team name\n",
    "            \n",
    "            total_home_goals = 0                               # counts total goals scored by home team over \"past\" matches\n",
    "            total_away_goals = 0                               # counts total goals scored by away team over \"past\" matches\n",
    "            \n",
    "            total_home_conceded = 0                            # counts total goals scored against home team over \"past\" matches \n",
    "            total_away_conceded = 0                            # counts total goals scored against away team over \"past\" matches\n",
    "            \n",
    "            total_home_shotson = 0                             # counts total shots on target taken by home team over...\n",
    "            total_away_shotson = 0                             # counts total shots on target taken by away team over...\n",
    "            \n",
    "            total_home_corners = 0                             # counts total corners taken by home team over...\n",
    "            total_away_corners = 0                             # counts total corners taken by away team over...\n",
    "            \n",
    "            home_PPG_pre = match.iat[0,8]                      # home team pre-match points per game (PPG)\n",
    "            away_PPG_pre = match.iat[0,9]                      # away team pre-match points per game (PPG)\n",
    "            \n",
    "            \n",
    "            previous = 1                                       # counts up to \"past\"\n",
    "            \n",
    "            \n",
    "            while previous <= past:\n",
    "\n",
    "                home_match_prev = season.loc[(season['home_team_name'] == home_team) & (season['Game Week'] == week-previous)]   # picking out home team's previous match\n",
    "                h_sc_idx = 12       # home team score index\n",
    "                h_shon_idx = 32     # home shots on target index\n",
    "                h_corn_idx = 20     # home corners index\n",
    "                h_ppg_idx = 10\n",
    "                \n",
    "                away_match_prev = season.loc[(season['away_team_name'] == away_team) & (season['Game Week'] == week-previous)]   # picking out away team's previous match\n",
    "                a_sc_idx = 13       # away team score index\n",
    "                a_shon_idx = 33     # away team shots on target index\n",
    "                a_corn_idx = 21     # away corners index\n",
    "                a_ppg_idx = 11\n",
    "                \n",
    "                # if home team name was not found in 'home_team_name' column...\n",
    "                if (home_match_prev.size == 0):\n",
    "                    home_match_prev = season.loc[(season['away_team_name'] == home_team) & (season['Game Week'] == week-previous)]   # picking out home team's previous match\n",
    "                    h_sc_idx = 13      # home team score index\n",
    "                    h_shon_idx = 33    # home shots on target index\n",
    "                    h_corn_idx = 21    # home corners index\n",
    "                    h_ppg_idx = 11\n",
    "                    \n",
    "                # if away team name was not found in 'away_team_name' column...\n",
    "                if (away_match_prev.size == 0):\n",
    "                    away_match_prev = season.loc[(season['home_team_name'] == away_team) & (season['Game Week'] == week-previous)]   # picking out away team's previous match\n",
    "                    a_sc_idx = 12      # away team score index\n",
    "                    a_shon_idx = 32    # away team shots on target index\n",
    "                    a_corn_idx = 20    # away corners index\n",
    "                    a_ppg_idx = 10\n",
    "                    \n",
    "                # if loop is 1 match in the past...   \n",
    "                if previous == 1:\n",
    "                    home_PPG = home_match_prev.iat[0,h_ppg_idx]\n",
    "                    away_PPG = away_match_prev.iat[0,a_ppg_idx]\n",
    "                    \n",
    "                #print(home_team, 'goals scored in week', week-previous, '= ', home_match_prev.iat[0,h_sc_idx])\n",
    "                total_home_goals += home_match_prev.iat[0,h_sc_idx]\n",
    "                total_away_goals += away_match_prev.iat[0,a_sc_idx]\n",
    "                \n",
    "                #print(home_team, 'goals conceded in week', week-previous, '=', home_match_prev.iat[0,a_sc_idx])\n",
    "                total_home_conceded += home_match_prev.iat[0,a_sc_idx]\n",
    "                total_away_conceded += away_match_prev.iat[0,h_sc_idx]\n",
    "                \n",
    "                total_home_shotson += home_match_prev.iat[0,h_shon_idx]\n",
    "                total_away_shotson += away_match_prev.iat[0,a_shon_idx]\n",
    "                \n",
    "                total_home_corners += home_match_prev.iat[0,h_corn_idx]\n",
    "                total_away_corners += away_match_prev.iat[0,a_corn_idx]\n",
    "                \n",
    "                \n",
    "                previous += 1\n",
    "\n",
    "            in_idx = row_idx - (past*10)\n",
    "            input_season[in_idx][0] = total_home_goals/past          # input INDEX 0 (home team avg. goals over \"past\")\n",
    "            input_season[in_idx][1] = total_home_conceded/past       # input INDEX 1 (home team avg. conceded goals over \"past\")\n",
    "            input_season[in_idx][2] = home_PPG_pre                   # input INDEX 2 (home team pre-match PPG: PPG in current season)\n",
    "            input_season[in_idx][3] = home_PPG                       # input INDEX 3 (home team PPG including past seasons)\n",
    "            input_season[in_idx][4] = total_home_shotson/past        # input INDEX 4 (home team avg. shots on target over \"past\")\n",
    "            input_season[in_idx][5] = total_home_corners/past        # input INDEX 5 (home team avg. corner kicks over \"past\")\n",
    "            input_season[in_idx][6] = total_away_goals/past          # input INDEX 6 (away team avg. goals over \"past\")\n",
    "            input_season[in_idx][7] = total_away_conceded/past       # input INDEX 7 (away team avg. conceded goals over \"past\")\n",
    "            input_season[in_idx][8] = away_PPG_pre                   # input INDEX 8 (away team pre-match PPG: PPG in current season)\n",
    "            input_season[in_idx][9] = away_PPG                       # input INDEX 9 (away team PPG including past seasons)\n",
    "            input_season[in_idx][10] = total_away_shotson/past       # input INDEX 10 (away team avg. shots on target over \"past\")\n",
    "            input_season[in_idx][11] = total_away_corners/past       # input INDEX 11 (away team avg. corner kicks over \"past\")\n",
    "            input_season[in_idx][12] = result                        # label INDEX 12 (match result)\n",
    "            \n",
    "            \n",
    "            row_idx += 1\n",
    "            match_count += 1\n",
    "\n",
    "        week += 1\n",
    "        \n",
    "    season_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining all season input data into one dataset\n",
    "data_full_np = np.concatenate((in_20, in_19, in_18, in_17, in_16, in_15, in_14, in_13), axis=0)\n",
    "\n",
    "# Turn numpy array back into pd.DataFrame\n",
    "columns = ['h_goals','h_conceded','h_prePPG','h_avgPPG','h_shotsOn','h_corners',\n",
    "           'a_goals','a_conceded','a_prePPG','a_avgPPG','a_shotsOn','a_corners',\n",
    "           'outcome']\n",
    "\n",
    "data_full = pd.DataFrame(data_full_np, columns=columns)\n",
    "\n",
    "# Print 'outcome' column sums to determine dataset balance\n",
    "# print('The numbers of match outcomes (Home Team Wins, Away Team Wins, Draws):', data_full[\"outcome\"].value_counts())\n",
    "\n",
    "# Get a better idea of what our data looks like BEFORE NORMALIZATION\n",
    "def verbose_print(data):     # helper function\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(data.head())\n",
    "       \n",
    "# print(\"\\n \\n Data characteristics:\")\n",
    "# verbose_print(data_full.describe())\n",
    "\n",
    "# Turn 'outcome' column values into one hot-encoded form\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(data_full_np[:,12])   # y is vector of 1-hot encoded labels\n",
    "\n",
    "#X = data_full_np[:,:12]                    # x is matrix of inputs (need to be normalized still)\n",
    "\n",
    "# Normalize continuous inputs\n",
    "X = data_full.drop(columns=['outcome'])\n",
    "\n",
    "for feature in X:\n",
    "  mean = X[feature].mean()\n",
    "  std = X[feature].std()\n",
    "  X[feature] = X[feature] - mean\n",
    "  X[feature] = X[feature]/std\n",
    "\n",
    "X = train_test_split(X,test_size=0.2,random_state=1)\n",
    "y = train_test_split(y,test_size=0.2,random_state=1)\n",
    "\n",
    "X_train = X[0]  # extracting training inputs\n",
    "y_train = y[0]  # extracting training labels\n",
    "X_infer = train_test_split(X[1],test_size = 0.33,random_state=1) # splitting inputs into validation and test sets\n",
    "y_infer = train_test_split(y[1],test_size = 0.33,random_state=1) # splitting labels into validation and test sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_QroHKoW2sd"
   },
   "source": [
    "## Multi-Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEdgVrZRW2sd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size,32)\n",
    "        self.fc2 = nn.Linear(32,32)\n",
    "        self.fc3 = nn.Linear(32,20)\n",
    "        self.fc4 = nn.Linear(20,3)   #output is 3 classes for home win, away win, tie\n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        features = F.relu(self.fc1(features))\n",
    "        features = F.relu(self.fc2(features))\n",
    "        features = F.relu(self.fc3(features))\n",
    "        features = F.relu(self.fc4(features))\n",
    "        features = torch.sigmoid(features)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bK461FjGZrXc"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MatchDataset turns matrix-style datasets into map-style datasets\n",
    "class MatchDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index,:],self.y[index]\n",
    "    \n",
    "\n",
    "def load_data(batch_size):\n",
    "\n",
    "    train_dataset = MatchDataset(X_train,y_train)\n",
    "    valid_dataset = MatchDataset(X_infer[0],y_infer[0])\n",
    "    test_dataset = MatchDataset(X_infer[1],y_infer[1])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M0Mu74T_7V0"
   },
   "source": [
    "#### Get prediction from output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnXEA5wlAAUu",
    "outputId": "c66bbc4b-2fd5-4d21-daaa-2d701e0bc1df"
   },
   "outputs": [],
   "source": [
    "def get_preds(z):\n",
    "  dims = z.size()\n",
    "  out = np.zeros(dims)\n",
    "  #inputs: output of model\n",
    "  #outputs: corresponding output to prediction\n",
    "  max_idxs = torch.max(z,1)[1]\n",
    "  print(max_idxs)\n",
    "  for entry,idx in enumerate(max_idxs,0):\n",
    "      for val in range(dims[1]):\n",
    "        if val == idx:\n",
    "          out[entry][val] = 1\n",
    "  return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErVMQAJVfGi6"
   },
   "source": [
    "#### Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GGnhmzFZzpc"
   },
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    #inputs: preds: array, labels:array \n",
    "    #output: overall accuracy\n",
    "    correct = 0\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == labels[i]:\n",
    "          correct +=1\n",
    "    return (correct/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJlCum_EBNLh"
   },
   "source": [
    "#### Validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8PwjiNodBWz"
   },
   "outputs": [],
   "source": [
    "def validate(model,val_loader,loss_fcn):\n",
    "  val_acc=[]\n",
    "  val_loss=[]\n",
    "  for epoch in range(0,num_epochs):\n",
    "    for i,data in enumerate(val_loader,0): #iterate over val_loader, start idx=0\n",
    "      inputs,labels = data  #val_loader idx0->data, idx1->labels\n",
    "      \n",
    "      labels = F.one_hot(labels) #convert labels 0:home 1:away 2:tie to vector. Ex: 0->[1,0,0] 1->[0,1,0], 2->[0,0,1]\n",
    "\n",
    "      optimizer.zero_grad()  #initialize the gradients to zero  \n",
    "\n",
    "      z = model(inputs)\n",
    "      \n",
    "      preds = get_preds(z) #preds used for accuracy \n",
    "      loss = loss_fcn(input=z.squeeze(), target=labels.float())\n",
    "\n",
    "      mini_val_acc.append(accuracy(preds,labels))\n",
    "      mini_val_loss.append(loss.item())\n",
    "\n",
    "  ValLoss = sum(val_loss)/len(val_loss)\n",
    "  ValAcc = sum(val_acc) / len(val_acc)\n",
    "  \n",
    "  return ValAcc, ValLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kAaa_MEjVrw"
   },
   "source": [
    "#### MLP loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3vF0n-IjUwj"
   },
   "outputs": [],
   "source": [
    "def load_MLP(lr):\n",
    "  #add optimizer,loss functions as a hyperparameters\n",
    "  model = MultiLayerPerceptron(input_size)\n",
    "  optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "  loss_fcn = nn.MSELoss()\n",
    "  return model,optimizer,loss_fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfaT7X6ZiWn_"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18YWlXsYim9y"
   },
   "outputs": [],
   "source": [
    "def train(rseed,lr,num_epochs):\n",
    "\n",
    "  torch.manual_seed(rseed)\n",
    "\n",
    "  model,optimizer,loss_fcn = load_MLP(lr)   #initialize model \n",
    "  soft = nn.SoftMax(dim=1) #create softmax act function\n",
    "\n",
    "\n",
    "  #records for plotting \n",
    "  TrainAccRec = []\n",
    "  TrainLossRec = []\n",
    "  ValAccRec = []  \n",
    "  ValLossRec = []\n",
    " \n",
    "# ========================================TRAINING LOOP =========================================# \n",
    "  for epoch in range(0,num_epochs):\n",
    "    for i,data in enumerate(train_loader,0): #iterate over train_loader, start idx=0\n",
    "      inputs,labels = data  #trainloader idx0->data, idx1->labels\n",
    "      \n",
    "      labels = F.one_hot(labels) #convert labels 0:home 1:away 2:tie to vector. Ex: 0->[1,0,0] 1->[0,1,0], 2->[0,0,1]\n",
    "\n",
    "      optimizer.zero_grad()  #initialize the gradients to zero  \n",
    "\n",
    "      z = model(inputs)  #z array of vector outputs, each size=3 \n",
    "\n",
    "      #z = soft(z)  #may not need since using sigmoid act fcn already\n",
    "\n",
    "      preds = get_preds(z) #preds used for accuracy \n",
    "\n",
    "      loss = loss_fcn(input=z.squeeze(), target=labels.float())\n",
    "\n",
    "      \n",
    "      loss.backward() #get gradients \n",
    "     \n",
    "      optimizer.step() #update parameters\n",
    "\n",
    "      train_acc = accuracy(preds,labels)\n",
    "      train_loss = loss.item()\n",
    "\n",
    "      val_acc, val_loss = validate(model, val_iter,loss_fcn)\n",
    "        \n",
    "    #add to overall records\n",
    "      TrainAccRec.append(train_acc)\n",
    "      TrainLossRec.append(train_loss)\n",
    "      ValAccRec.append(epoch_val_acc)\n",
    "      ValLossRec.append(epoch_val_loss)\n",
    "\n",
    "    # print(\"Epoch:\",epoch+1)\n",
    "    # print(\"train acc:\",epoch_train_acc)\n",
    "    # print(\"val acc:\",epoch_val_acc)\n",
    " \n",
    "    \n",
    "\n",
    "#plottting\n",
    "  e = np.arange(0,num_epochs)\n",
    "  plot(e,TrainAccRec,ValAccRec,'Epochs','Accuracy')\n",
    "  plot(e,TrainLossRec,ValLossRec,'Epochs','Losses')\n",
    "  print(\"Max training accuracy\",max(TrainAccRec))\n",
    "  print(\"Max Validation accuracy\",max(ValAccRec))\n",
    "  print(\"Min training loss\",min(TrainLossRec))\n",
    "  print(\"Min Validation loss\",min(ValLossRec))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Is0DNAr7W2sc",
    "A3RvsJpwW2sc",
    "m_1ZIfpIW2sc",
    "ErVMQAJVfGi6"
   ],
   "name": "MatchPredictor_MLP-checkpoint.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
