{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MatchPredictor_MLP.ipynb","provenance":[{"file_id":"17ZM0caStMWVcCB1zBCeZeX2vyD1xzWOH","timestamp":1606619149195}],"collapsed_sections":["kJlCum_EBNLh","WbQCrISXWN46"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"J4WnfXTuW2sb"},"source":["# MatchPredictor\n","\n","### A neural network which predicts the outcomes of Premier League football matches"]},{"cell_type":"markdown","metadata":{"id":"A4uLPYGzW2sb"},"source":["#### Importing Libraries & Packages"]},{"cell_type":"code","metadata":{"id":"L3D867YUW2sb","executionInfo":{"status":"ok","timestamp":1606624657942,"user_tz":300,"elapsed":364,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.utils.data \n","\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n"],"execution_count":158,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ukm7le4QW2sc"},"source":["#### Hyperparameters"]},{"cell_type":"code","metadata":{"id":"1k1mUJUiW2sc","executionInfo":{"status":"ok","timestamp":1606624516024,"user_tz":300,"elapsed":513,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["past = 5    # How many past games are taken into account for team form calculations\n","rseed = 1 \n","batch_size = 32\n","num_epochs = 5\n","# fc1_size = 32\n","# fc2_size = 32\n","# fc3_size = 20\n","# out_size = 3\n","input_size = 12\n","h_sizes  = [12,32,32,20,3]\n","act=\"relu\"\n","            #add num hidden layers, optimizer loss fcn\n","lr = 0.01 "],"execution_count":156,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Is0DNAr7W2sc"},"source":["#### Importing Match Data"]},{"cell_type":"code","metadata":{"id":"fC0-M0RiW2sc","executionInfo":{"status":"ok","timestamp":1606622631771,"user_tz":300,"elapsed":748,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["# Imported CSV becomes a pandas dataframe object\n","\n","data_20 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2019-to-2020-stats.csv\")\n","data_19 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2018-to-2019-stats.csv\")\n","data_18 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2017-to-2018-stats.csv\")\n","data_17 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2016-to-2017-stats.csv\")\n","data_16 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2015-to-2016-stats.csv\")\n","data_15 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2014-to-2015-stats.csv\")\n","data_14 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2013-to-2014-stats.csv\")\n","data_13 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2012-to-2013-stats.csv\")\n","\n","\n","data = [data_20, data_19, data_18, data_17, data_16, data_15, data_14, data_13]"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5MN-9bL31cN","executionInfo":{"status":"ok","timestamp":1606622631773,"user_tz":300,"elapsed":734,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}},"outputId":"eafe127d-4381-4b87-81be-f09312a63fbe"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":124,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m_1ZIfpIW2sc"},"source":["#### DATA PREPROCSESSING  \n","  \n","Here we create the inputs for our model from the raw .csv files we collected from *footystats.org*.  \n","  \n","- Each season will be represented by a matrix.  \n","- Each row of this matrix will consist of the inputs that describe a single match to the neural net.  \n","  \n","In each row, the entries are as follows:  \n","*Note: **past** is an integer hyperparameter*  \n","  \n","**Index 0**: Home team average goals scored per game over last **past** games.  \n","**Index 1**:  Home team average goals conceded per game over last **past** games.  \n","**Index 2**:  Home team pre-match PPG.  \n","**Index 3**:  Home team ppg from last game (so current game isn’t included).  \n","**Index 4**:  Home team average number of shots on target over last **past** games.  \n","**Index 5**:  Home team average number of corners over last **past** games.  \n","**Index 6**:  Away team average goals scored per game over last **past** games.  \n","**Index 7**:  Away team average goals conceded per game over last **past** games.  \n","**Index 8**:  Away team pre-match PPG.  \n","**Index 9**:  Away team ppg from last game (so current game isn’t included).  \n","**Index 10**:  Away team average number of shots on target over last **past** games.  \n","**Index 11**:  Away team average number of corners over last **past** games.  \n","**Index 12 (LABEL)**:  0 if Home Team won, 1 if Away Team won, 2 if Draw. \n","  \n","  \n","*NOTE: The first \"past\" weeks from each season cannot be used in training/testing as they have no previous matches to get data from.*"]},{"cell_type":"code","metadata":{"id":"Amz4WMIWW2sc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606622667967,"user_tz":300,"elapsed":36915,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}},"outputId":"e149d63b-8f00-4cde-fb27-62884f97c22b"},"source":["# Set up empty matrices to be filled with INPUTS.\n","# Once filled with values, each row will represent the inputs that describe a match to the NN.\n","    \n","in_20 = np.zeros((380-(past*10),13))\n","in_19 = np.zeros((380-(past*10),13))\n","in_18 = np.zeros((380-(past*10),13))\n","in_17 = np.zeros((380-(past*10),13))\n","in_16 = np.zeros((380-(past*10),13))\n","in_15 = np.zeros((380-(past*10),13))\n","in_14 = np.zeros((380-(past*10),13))\n","in_13 = np.zeros((380-(past*10),13))\n","\n","\n","input_seasons = [in_20, in_19, in_18, in_17, in_16, in_15, in_14, in_13]\n","\n","\n","season_idx = 0\n","for season in data:\n","    \n","    week = past + 1\n","    input_season = input_seasons[season_idx]\n","    \n","    \n","    while week < 39:\n","        \n","        row_idx = (week-1)*10             # index of the first match of new week\n","        match_count = 0                   # counting the 10 matches played in a given week\n","\n","        \n","        while match_count < 10:\n","            \n","            match = season.iloc[[row_idx]]                     # saving current match\n","            \n","             # getting match LABEL (match result)\n","            if (match.iat[0,12] > match.iat[0,13]):            \n","                    result = 0   # home team win\n","            elif (match.iat[0,12] < match.iat[0,13]):\n","                    result = 1   # away team win\n","            else:\n","                    result = 2   # draw\n","                    \n","            \n","            home_team = season.at[row_idx,'home_team_name']    # saving home team name\n","            away_team = season.at[row_idx,'away_team_name']    # saving away team name\n","            \n","            total_home_goals = 0                               # counts total goals scored by home team over \"past\" matches\n","            total_away_goals = 0                               # counts total goals scored by away team over \"past\" matches\n","            \n","            total_home_conceded = 0                            # counts total goals scored against home team over \"past\" matches \n","            total_away_conceded = 0                            # counts total goals scored against away team over \"past\" matches\n","            \n","            total_home_shotson = 0                             # counts total shots on target taken by home team over...\n","            total_away_shotson = 0                             # counts total shots on target taken by away team over...\n","            \n","            total_home_corners = 0                             # counts total corners taken by home team over...\n","            total_away_corners = 0                             # counts total corners taken by away team over...\n","            \n","            home_PPG_pre = match.iat[0,8]                      # home team pre-match points per game (PPG)\n","            away_PPG_pre = match.iat[0,9]                      # away team pre-match points per game (PPG)\n","            \n","            \n","            previous = 1                                       # counts up to \"past\"\n","            \n","            \n","            while previous <= past:\n","\n","                home_match_prev = season.loc[(season['home_team_name'] == home_team) & (season['Game Week'] == week-previous)]   # picking out home team's previous match\n","                h_sc_idx = 12       # home team score index\n","                h_shon_idx = 32     # home shots on target index\n","                h_corn_idx = 20     # home corners index\n","                h_ppg_idx = 10\n","                \n","                away_match_prev = season.loc[(season['away_team_name'] == away_team) & (season['Game Week'] == week-previous)]   # picking out away team's previous match\n","                a_sc_idx = 13       # away team score index\n","                a_shon_idx = 33     # away team shots on target index\n","                a_corn_idx = 21     # away corners index\n","                a_ppg_idx = 11\n","                \n","                # if home team name was not found in 'home_team_name' column...\n","                if (home_match_prev.size == 0):\n","                    home_match_prev = season.loc[(season['away_team_name'] == home_team) & (season['Game Week'] == week-previous)]   # picking out home team's previous match\n","                    h_sc_idx = 13      # home team score index\n","                    h_shon_idx = 33    # home shots on target index\n","                    h_corn_idx = 21    # home corners index\n","                    h_ppg_idx = 11\n","                    \n","                # if away team name was not found in 'away_team_name' column...\n","                if (away_match_prev.size == 0):\n","                    away_match_prev = season.loc[(season['home_team_name'] == away_team) & (season['Game Week'] == week-previous)]   # picking out away team's previous match\n","                    a_sc_idx = 12      # away team score index\n","                    a_shon_idx = 32    # away team shots on target index\n","                    a_corn_idx = 20    # away corners index\n","                    a_ppg_idx = 10\n","                    \n","                # if loop is 1 match in the past...   \n","                if previous == 1:\n","                    home_PPG = home_match_prev.iat[0,h_ppg_idx]\n","                    away_PPG = away_match_prev.iat[0,a_ppg_idx]\n","                    \n","                #print(home_team, 'goals scored in week', week-previous, '= ', home_match_prev.iat[0,h_sc_idx])\n","                total_home_goals += home_match_prev.iat[0,h_sc_idx]\n","                total_away_goals += away_match_prev.iat[0,a_sc_idx]\n","                \n","                #print(home_team, 'goals conceded in week', week-previous, '=', home_match_prev.iat[0,a_sc_idx])\n","                total_home_conceded += home_match_prev.iat[0,a_sc_idx]\n","                total_away_conceded += away_match_prev.iat[0,h_sc_idx]\n","                \n","                total_home_shotson += home_match_prev.iat[0,h_shon_idx]\n","                total_away_shotson += away_match_prev.iat[0,a_shon_idx]\n","                \n","                total_home_corners += home_match_prev.iat[0,h_corn_idx]\n","                total_away_corners += away_match_prev.iat[0,a_corn_idx]\n","                \n","                \n","                previous += 1\n","\n","            in_idx = row_idx - (past*10)\n","            input_season[in_idx][0] = total_home_goals/past          # input INDEX 0 (home team avg. goals over \"past\")\n","            input_season[in_idx][1] = total_home_conceded/past       # input INDEX 1 (home team avg. conceded goals over \"past\")\n","            input_season[in_idx][2] = home_PPG_pre                   # input INDEX 2 (home team pre-match PPG: PPG in current season)\n","            input_season[in_idx][3] = home_PPG                       # input INDEX 3 (home team PPG including past seasons)\n","            input_season[in_idx][4] = total_home_shotson/past        # input INDEX 4 (home team avg. shots on target over \"past\")\n","            input_season[in_idx][5] = total_home_corners/past        # input INDEX 5 (home team avg. corner kicks over \"past\")\n","            input_season[in_idx][6] = total_away_goals/past          # input INDEX 6 (away team avg. goals over \"past\")\n","            input_season[in_idx][7] = total_away_conceded/past       # input INDEX 7 (away team avg. conceded goals over \"past\")\n","            input_season[in_idx][8] = away_PPG_pre                   # input INDEX 8 (away team pre-match PPG: PPG in current season)\n","            input_season[in_idx][9] = away_PPG                       # input INDEX 9 (away team PPG including past seasons)\n","            input_season[in_idx][10] = total_away_shotson/past       # input INDEX 10 (away team avg. shots on target over \"past\")\n","            input_season[in_idx][11] = total_away_corners/past       # input INDEX 11 (away team avg. corner kicks over \"past\")\n","            input_season[in_idx][12] = result                        # label INDEX 12 (match result)\n","            \n","            #print(input_season[in_idx])\n","            \n","            row_idx += 1\n","            match_count += 1\n","\n","        week += 1\n","        \n","    season_idx += 1\n","      \n","        \n","print('19/20 season input matrix: \\n', in_20, '\\n')\n","print('18/19 season input matrix: \\n', in_19, '\\n')\n","print('17/18 season input matrix: \\n', in_18, '\\n')\n","print('16/17 season input matrix: \\n', in_17, '\\n')\n","print('15/16 season input matrix: \\n', in_16, '\\n')\n","print('14/15 season input matrix: \\n', in_15, '\\n')\n","print('13/14 season input matrix: \\n', in_14, '\\n')\n","print('12/13 season input matrix: \\n', in_13, '\\n')"],"execution_count":125,"outputs":[{"output_type":"stream","text":["19/20 season input matrix: \n"," [[1.   1.2  0.5  ... 5.2  4.8  1.  ]\n"," [1.2  0.8  2.   ... 6.4  6.4  0.  ]\n"," [1.2  1.4  1.5  ... 6.   3.   0.  ]\n"," ...\n"," [0.8  1.4  1.44 ... 8.   9.4  1.  ]\n"," [1.4  0.8  1.   ... 3.8  6.2  0.  ]\n"," [2.   0.8  1.17 ... 5.   5.2  2.  ]] \n","\n","18/19 season input matrix: \n"," [[ 1.4   2.    1.5  ...  5.8   5.    2.  ]\n"," [ 0.6   2.    0.   ...  5.    5.4   0.  ]\n"," [ 0.6   1.2   0.5  ... 10.2   8.4   1.  ]\n"," ...\n"," [ 1.6   2.2   1.22 ...  3.4   3.8   2.  ]\n"," [ 1.    0.8   2.06 ...  5.8   8.    2.  ]\n"," [ 1.4   1.6   1.5  ...  5.6   6.    1.  ]] \n","\n","17/18 season input matrix: \n"," [[0.8  1.2  3.   ... 7.8  9.   1.  ]\n"," [1.2  1.   1.5  ... 5.2  6.4  2.  ]\n"," [0.4  2.   1.5  ... 3.6  4.2  0.  ]\n"," ...\n"," [0.4  1.8  1.17 ... 4.4  2.6  1.  ]\n"," [1.2  1.2  2.22 ... 3.2  7.2  0.  ]\n"," [1.2  2.   1.33 ... 3.6  3.2  0.  ]] \n","\n","16/17 season input matrix: \n"," [[1.6  2.   1.5  ... 5.2  4.6  0.  ]\n"," [0.6  1.2  1.5  ... 7.8  5.8  0.  ]\n"," [2.2  1.2  3.   ... 3.4  4.   0.  ]\n"," ...\n"," [0.8  0.6  1.33 ... 5.   5.2  1.  ]\n"," [1.2  0.4  1.33 ... 3.8  4.6  0.  ]\n"," [0.2  1.4  1.56 ... 9.6  8.8  1.  ]] \n","\n","15/16 season input matrix: \n"," [[ 1.4   1.8   0.5  ... 10.4   8.    0.  ]\n"," [ 1.4   1.    3.   ...  5.2   6.8   2.  ]\n"," [ 0.6   1.2   0.   ...  4.    4.    2.  ]\n"," ...\n"," [ 1.4   1.    1.39 ...  4.4   6.4   0.  ]\n"," [ 0.6   3.    1.39 ...  3.8   7.4   0.  ]\n"," [ 1.    1.    2.11 ...  4.4   6.6   0.  ]] \n","\n","14/15 season input matrix: \n"," [[1.4  1.6  1.5  ... 3.8  5.   2.  ]\n"," [3.2  2.2  3.   ... 1.8  5.8  0.  ]\n"," [1.6  2.   0.5  ... 2.4  4.   0.  ]\n"," ...\n"," [3.2  1.2  2.33 ... 3.4  5.6  0.  ]\n"," [1.   2.4  1.28 ... 4.4  7.   0.  ]\n"," [1.2  0.8  1.67 ... 6.6  5.6  0.  ]] \n","\n","13/14 season input matrix: \n"," [[1.   0.2  3.   ... 5.2  5.4  2.  ]\n"," [1.2  1.2  0.   ... 4.8  7.   0.  ]\n"," [0.6  1.2  0.5  ... 2.2  2.8  1.  ]\n"," ...\n"," [1.6  1.4  1.   ... 4.4  5.4  1.  ]\n"," [2.4  2.8  1.83 ... 4.6  5.   0.  ]\n"," [1.2  1.4  1.17 ... 4.4  4.2  1.  ]] \n","\n","12/13 season input matrix: \n"," [[1.8  0.4  2.   ... 8.6  4.2  1.  ]\n"," [1.8  1.   2.   ... 6.6  4.2  0.  ]\n"," [2.4  2.2  3.   ... 9.2  6.6  1.  ]\n"," ...\n"," [1.2  2.   1.67 ... 6.6  4.6  2.  ]\n"," [0.8  1.   1.67 ... 7.2  5.6  0.  ]\n"," [1.6  2.2  0.94 ... 8.   5.2  2.  ]] \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bNmJ7F2e0c8L","executionInfo":{"status":"ok","timestamp":1606622667969,"user_tz":300,"elapsed":36908,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["# Joining all season input data into one dataset\n","data_full_np = np.concatenate((in_20, in_19, in_18, in_17, in_16, in_15, in_14, in_13), axis=0)\n","\n","# Turn numpy array back into pd.DataFrame\n","columns = ['h_goals','h_conceded','h_prePPG','h_avgPPG','h_shotsOn','h_corners',\n","           'a_goals','a_conceded','a_prePPG','a_avgPPG','a_shotsOn','a_corners',\n","           'outcome']\n","\n","data_full = pd.DataFrame(data_full_np, columns=columns)\n","\n","# Print 'outcome' column sums to determine dataset balance\n","# print('The numbers of match outcomes (Home Team Wins, Away Team Wins, Draws):', data_full[\"outcome\"].value_counts())\n","\n","# Get a better idea of what our data looks like BEFORE NORMALIZATION\n","def verbose_print(data):     # helper function\n","    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n","        print(data.head())\n","       \n","# print(\"\\n \\n Data characteristics:\")\n","# verbose_print(data_full.describe())\n","\n","# Turn 'outcome' column values into one hot-encoded form\n","lb = LabelBinarizer()\n","y = lb.fit_transform(data_full_np[:,12])   # y is vector of 1-hot encoded labels\n","\n","#X = data_full_np[:,:12]                    # x is matrix of inputs (need to be normalized still)\n","\n","# Normalize continuous inputs\n","X = data_full.drop(columns=['outcome'])\n","\n","for feature in X:\n","  mean = X[feature].mean()\n","  std = X[feature].std()\n","  X[feature] = X[feature] - mean\n","  X[feature] = X[feature]/std\n","\n","X = X.values\n","X = train_test_split(X,test_size=0.2,random_state=1)\n","y = train_test_split(y,test_size=0.2,random_state=1)\n","\n","X_train = X[0]  # extracting training inputs\n","y_train = y[0]  # extracting training labels\n","X_infer = train_test_split(X[1],test_size = 0.33,random_state=1) # splitting inputs into validation and test sets\n","y_infer = train_test_split(y[1],test_size = 0.33,random_state=1) # splitting labels into validation and test sets"],"execution_count":126,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P_QroHKoW2sd"},"source":["## Multi-Layer Perceptron Model"]},{"cell_type":"code","metadata":{"id":"uEdgVrZRW2sd","executionInfo":{"status":"ok","timestamp":1606623416201,"user_tz":300,"elapsed":386,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["class MultiLayerPerceptron(nn.Module):\n","\n","    def __init__(self, input_size,h_sizes,act):\n","      #current parameters are:\n","        #input size = matrix size\n","        #h_sizes = list of each layer size ->ex: [12,32,32,20,3]\n","        #MAKE SURE LAST HID_LAYER OUTPUTS TO 3\n","        #act_fcn = ?\n","        super(MultiLayerPerceptron, self).__init__()\n","        # self.hidden = nn.ModuleList()\n","        # for k in range(len(h_sizes)-2):\n","        #     self.hidden.append(nn.Linear(h_sizes[k], h_sizes[k+1]))\n","\n","        if act =='relu':\n","          self.act = nn.ReLU()\n","        elif act == 'sigmoid':  \n","          self.act = nn.sigmoid()\n","        self.out = nn.Softmax()\n","\n","\n","        self.fc1 = nn.Linear(input_size,32)\n","        self.fc2 = nn.Linear(32,32)\n","        self.fc3 = nn.Linear(32,20)\n","        self.fc4 = nn.Linear(20,3)   #output is 3 classes for home win, away win, tie\n","\n","    def forward(self, x):\n","      # for i in self.hidden:\n","      #   x = self.act(self.hidden[i])\n","      # x =  self.out(x)\n","\n","      x = F.relu(self.fc1(x))\n","      x = F.relu(self.fc2(x))\n","      x = F.relu(self.fc3(x))\n","      x = F.sigmoid(self.fc4(x))\n","      return x"],"execution_count":142,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bK461FjGZrXc"},"source":["###Helper Functions"]},{"cell_type":"markdown","metadata":{"id":"qE-dBefR_wCv"},"source":["#### Dataloader creation\n"]},{"cell_type":"code","metadata":{"id":"Bf7SrNHz_xq7","executionInfo":{"status":"ok","timestamp":1606622667976,"user_tz":300,"elapsed":36903,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["# MatchDataset turns matrix-style datasets into map-style datasets\n","class MatchDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, index):\n","        return self.X[index],self.y[index]\n","    \n","\n","def load_data(batch_size):\n","\n","    train_dataset = MatchDataset(X_train,y_train)\n","    valid_dataset = MatchDataset(X_infer[0],y_infer[0])\n","    test_dataset = MatchDataset(X_infer[1],y_infer[1])\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True) \n","\n","    return train_loader, valid_loader, test_loader\n","\n","train_loader, valid_loader, test_loader = load_data(batch_size)\n","\n","\n","\n"],"execution_count":128,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2M0Mu74T_7V0"},"source":["#### Get prediction from output"]},{"cell_type":"code","metadata":{"id":"tnXEA5wlAAUu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606624469731,"user_tz":300,"elapsed":494,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}},"outputId":"3a7a5b1a-bbe0-4902-dafd-f3e544f80d1a"},"source":["def get_preds(z):\n","  out = np.zeros(z.shape)\n","  #inputs: output of model\n","  #outputs: corresponding output to prediction\n","  max_idxs = torch.max(z,1)[1]\n","  for entry,idx in enumerate(max_idxs,0):\n","      for val in range(3):\n","        if val == idx:\n","          out[entry][val] = 1\n","  return out\n","\n","a=torch.randn(4,3)\n","print(a)\n","b=get_preds(a)\n","print(b)"],"execution_count":154,"outputs":[{"output_type":"stream","text":["tensor([[-1.1328,  1.2251,  0.0999],\n","        [-0.0077,  0.7902,  0.9473],\n","        [ 1.1566,  0.6758, -0.1526],\n","        [-0.2415,  1.8156, -0.6180]])\n","[[0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ErVMQAJVfGi6"},"source":["####accuracy function"]},{"cell_type":"code","metadata":{"id":"5GGnhmzFZzpc","executionInfo":{"status":"ok","timestamp":1606622667979,"user_tz":300,"elapsed":36893,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["def accuracy(preds, labels):\n","    #inputs: preds: array, labels:array \n","    #output: overall accuracy\n","    correct = 0\n","    for i in range(len(preds)):\n","        if preds[i] == labels[i]:\n","          correct +=1\n","    return (correct/len(preds))"],"execution_count":130,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kJlCum_EBNLh"},"source":["####validate "]},{"cell_type":"code","metadata":{"id":"H8PwjiNodBWz","executionInfo":{"status":"ok","timestamp":1606623722014,"user_tz":300,"elapsed":613,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["def validate(model,val_loader,loss_fcn):\n","  val_acc=[]\n","  val_loss=[]\n","  for epoch in range(0,num_epochs):\n","    for i,data in enumerate(val_loader,0): #iterate over val_loader, start idx=0\n","      inputs,labels = data\n","\n","      z = model(inputs.float())  #z is size=3 \n","\n","      preds = get_preds(z) #preds used for accuracy \n","\n","      loss = loss_fcn(input=z.squeeze(), target=labels.float())\n","\n","      val_acc.append(accuracy(preds,labels))\n","      val_loss.append(loss.item())\n","\n","  ValLoss = sum(val_loss)/len(val_loss)\n","  ValAcc = sum(val_acc) / len(val_acc)\n","  \n","  return ValAcc, ValLoss"],"execution_count":148,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WbQCrISXWN46"},"source":["#### plotting function"]},{"cell_type":"code","metadata":{"id":"Sd9apCNOWOHQ","executionInfo":{"status":"ok","timestamp":1606622668116,"user_tz":300,"elapsed":37021,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["def plot(epoch, train_var, val_var,xlabel,ylabel):\n","    plt.plot(epoch, train_var, label = 'train')\n","    plt.plot(epoch, val_var, label = 'validation')\n","    plt.title(str(xlabel) + ' vs. '+str(ylabel))\n","    plt.xlabel(str(xlabel))\n","    plt.ylabel(str(ylabel))\n","    plt.legend()\n","    plt.show()"],"execution_count":132,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7kAaa_MEjVrw"},"source":["#### MLP loader"]},{"cell_type":"code","metadata":{"id":"Q3vF0n-IjUwj","executionInfo":{"status":"ok","timestamp":1606622668118,"user_tz":300,"elapsed":37019,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}}},"source":["def load_MLP(lr):\n","  #add optimizer,loss functions as a hyperparameters\n","  model = MultiLayerPerceptron(input_size,h_sizes,act)\n","  optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n","  loss_fcn = nn.MSELoss()\n","  return model,optimizer,loss_fcn"],"execution_count":133,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZfaT7X6ZiWn_"},"source":["##Training Loop"]},{"cell_type":"code","metadata":{"id":"18YWlXsYim9y","colab":{"base_uri":"https://localhost:8080/","height":700},"executionInfo":{"status":"error","timestamp":1606624724099,"user_tz":300,"elapsed":50034,"user":{"displayName":"atom arce","photoUrl":"","userId":"07689925988492945351"}},"outputId":"10a03527-aa1f-4fe4-da11-5721d03e8315"},"source":["def train(rseed,lr,num_epochs):\n","\n","  torch.manual_seed(rseed)\n","\n","  model,optimizer,loss_fcn = load_MLP(lr)   #initialize model \n","\n","\n","\n","  #records for plotting \n","  TrainAccRec = []\n","  TrainLossRec = []\n","  ValAccRec = []  \n","  ValLossRec = []\n"," \n","# ========================================TRAINING LOOP =========================================# \n","  for epoch in range(0,num_epochs):\n","    for i,data in enumerate(train_loader,0): #iterate over train_loader, start idx=0\n","      inputs,labels = data\n","\n","      optimizer.zero_grad()  #initialize the gradients to zero  \n","\n","      z = model(inputs.float())  #z is size=3 \n","\n","      preds = get_preds(z) #preds used for accuracy \n","\n","      loss = loss_fcn(input=z.squeeze(), target=labels.float())\n","\n","      \n","      loss.backward() #get gradients \n","     \n","      optimizer.step() #update parameters\n","\n","      train_acc = accuracy(preds,labels)\n","      train_loss = loss.item()\n","\n","      val_acc, val_loss = validate(model, valid_loader,loss_fcn)\n","        \n","    #add to overall records\n","      TrainAccRec.append(train_acc)\n","      TrainLossRec.append(train_loss)\n","      ValAccRec.append(val_acc)\n","      ValLossRec.append(val_loss)\n","\n","    print(\"Epoch:\",epoch+1)\n","    print(\"train acc:\",train_acc)\n","    print(\"val acc:\",val_acc)\n"," \n","    \n","\n","#plottting\n","  e = np.arange(0,num_epochs)\n","  plot(e,TrainAccRec,ValAccRec,'Epochs','Accuracy')\n","  plot(e,TrainLossRec,ValLossRec,'Epochs','Losses')\n","  print(\"Max training accuracy\",max(TrainAccRec))\n","  print(\"Max Validation accuracy\",max(ValAccRec))\n","  print(\"Min training loss\",min(TrainLossRec))\n","  print(\"Min Validation loss\",min(ValLossRec))\n","\n","\n","train(rseed,lr,num_epochs)  "],"execution_count":159,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([1, 3])) that is different to the input size (torch.Size([3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1\n","train acc: 0.0\n","val acc: 0.0\n","Epoch: 2\n","train acc: 0.0\n","val acc: 0.0\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: eq() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!)\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-159-feec7b6aa5ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-159-feec7b6aa5ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(rseed, lr, num_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#add to overall records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-148-6ed93d7d8a65>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader, loss_fcn)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mval_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-130-3e54cf7f1e5e>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(preds, labels)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m           \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}