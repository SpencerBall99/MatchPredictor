{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MatchPredictor_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kJlCum_EBNLh",
        "WbQCrISXWN46"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4WnfXTuW2sb"
      },
      "source": [
        "# MatchPredictor\n",
        "\n",
        "### A neural network which predicts the outcomes of Premier League football matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4uLPYGzW2sb"
      },
      "source": [
        "#### Importing Libraries & Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3D867YUW2sb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.utils.data \n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukm7le4QW2sc"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k1mUJUiW2sc"
      },
      "source": [
        "past = 5    # How many past games are taken into account for team form calculations\n",
        "rseed = 1 \n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "# fc1_size = 32\n",
        "# fc2_size = 32\n",
        "# fc3_size = 20\n",
        "# out_size = 3\n",
        "input_size = 12\n",
        "h_sizes  = [12,32,32,20,3]\n",
        "act=\"relu\"\n",
        "            #add num hidden layers, optimizer loss fcn\n",
        "lr = 0.01 "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is0DNAr7W2sc"
      },
      "source": [
        "#### Importing Match Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC0-M0RiW2sc"
      },
      "source": [
        "# Imported CSV becomes a pandas dataframe object\n",
        "\n",
        "data_20 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2019-to-2020-stats.csv\")\n",
        "data_19 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2018-to-2019-stats.csv\")\n",
        "data_18 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2017-to-2018-stats.csv\")\n",
        "data_17 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2016-to-2017-stats.csv\")\n",
        "data_16 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2015-to-2016-stats.csv\")\n",
        "data_15 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2014-to-2015-stats.csv\")\n",
        "data_14 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2013-to-2014-stats.csv\")\n",
        "data_13 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/MI/FINAL PROJECT/england-premier-league-matches-2012-to-2013-stats.csv\")\n",
        "\n",
        "\n",
        "data = [data_20, data_19, data_18, data_17, data_16, data_15, data_14, data_13]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TC4B4dNRFBk",
        "outputId": "c2fe9c74-d3e3-4885-b30c-cb378577fec7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_1ZIfpIW2sc"
      },
      "source": [
        "#### DATA PREPROCSESSING  \n",
        "  \n",
        "Here we create the inputs for our model from the raw .csv files we collected from *footystats.org*.  \n",
        "  \n",
        "- Each season will be represented by a matrix.  \n",
        "- Each row of this matrix will consist of the inputs that describe a single match to the neural net.  \n",
        "  \n",
        "In each row, the entries are as follows:  \n",
        "*Note: **past** is an integer hyperparameter*  \n",
        "  \n",
        "**Index 0**: Home team average goals scored per game over last **past** games.  \n",
        "**Index 1**:  Home team average goals conceded per game over last **past** games.  \n",
        "**Index 2**:  Home team pre-match PPG.  \n",
        "**Index 3**:  Home team ppg from last game (so current game isn’t included).  \n",
        "**Index 4**:  Home team average number of shots on target over last **past** games.  \n",
        "**Index 5**:  Home team average number of corners over last **past** games.  \n",
        "**Index 6**:  Away team average goals scored per game over last **past** games.  \n",
        "**Index 7**:  Away team average goals conceded per game over last **past** games.  \n",
        "**Index 8**:  Away team pre-match PPG.  \n",
        "**Index 9**:  Away team ppg from last game (so current game isn’t included).  \n",
        "**Index 10**:  Away team average number of shots on target over last **past** games.  \n",
        "**Index 11**:  Away team average number of corners over last **past** games.  \n",
        "**Index 12 (LABEL)**:  0 if Home Team won, 1 if Away Team won, 2 if Draw. \n",
        "  \n",
        "  \n",
        "*NOTE: The first \"past\" weeks from each season cannot be used in training/testing as they have no previous matches to get data from.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amz4WMIWW2sc",
        "outputId": "2fa7931f-8e83-40de-e21f-c5c07f3cda6d"
      },
      "source": [
        "# Set up empty matrices to be filled with INPUTS.\n",
        "# Once filled with values, each row will represent the inputs that describe a match to the NN.\n",
        "    \n",
        "in_20 = np.zeros((380-(past*10),13))\n",
        "in_19 = np.zeros((380-(past*10),13))\n",
        "in_18 = np.zeros((380-(past*10),13))\n",
        "in_17 = np.zeros((380-(past*10),13))\n",
        "in_16 = np.zeros((380-(past*10),13))\n",
        "in_15 = np.zeros((380-(past*10),13))\n",
        "in_14 = np.zeros((380-(past*10),13))\n",
        "in_13 = np.zeros((380-(past*10),13))\n",
        "\n",
        "\n",
        "input_seasons = [in_20, in_19, in_18, in_17, in_16, in_15, in_14, in_13]\n",
        "\n",
        "\n",
        "season_idx = 0\n",
        "for season in data:\n",
        "    \n",
        "    week = past + 1\n",
        "    input_season = input_seasons[season_idx]\n",
        "    \n",
        "    \n",
        "    while week < 39:\n",
        "        \n",
        "        row_idx = (week-1)*10             # index of the first match of new week\n",
        "        match_count = 0                   # counting the 10 matches played in a given week\n",
        "\n",
        "        \n",
        "        while match_count < 10:\n",
        "            \n",
        "            match = season.iloc[[row_idx]]                     # saving current match\n",
        "            \n",
        "             # getting match LABEL (match result)\n",
        "            if (match.iat[0,12] > match.iat[0,13]):            \n",
        "                    result = 0   # home team win\n",
        "            elif (match.iat[0,12] < match.iat[0,13]):\n",
        "                    result = 1   # away team win\n",
        "            else:\n",
        "                    result = 2   # draw\n",
        "                    \n",
        "            \n",
        "            home_team = season.at[row_idx,'home_team_name']    # saving home team name\n",
        "            away_team = season.at[row_idx,'away_team_name']    # saving away team name\n",
        "            \n",
        "            total_home_goals = 0                               # counts total goals scored by home team over \"past\" matches\n",
        "            total_away_goals = 0                               # counts total goals scored by away team over \"past\" matches\n",
        "            \n",
        "            total_home_conceded = 0                            # counts total goals scored against home team over \"past\" matches \n",
        "            total_away_conceded = 0                            # counts total goals scored against away team over \"past\" matches\n",
        "            \n",
        "            total_home_shotson = 0                             # counts total shots on target taken by home team over...\n",
        "            total_away_shotson = 0                             # counts total shots on target taken by away team over...\n",
        "            \n",
        "            total_home_corners = 0                             # counts total corners taken by home team over...\n",
        "            total_away_corners = 0                             # counts total corners taken by away team over...\n",
        "            \n",
        "            home_PPG_pre = match.iat[0,8]                      # home team pre-match points per game (PPG)\n",
        "            away_PPG_pre = match.iat[0,9]                      # away team pre-match points per game (PPG)\n",
        "            \n",
        "            \n",
        "            previous = 1                                       # counts up to \"past\"\n",
        "            \n",
        "            \n",
        "            while previous <= past:\n",
        "\n",
        "                home_match_prev = season.loc[(season['home_team_name'] == home_team) & (season['Game Week'] == week-previous)]   # picking out home team's previous match\n",
        "                h_sc_idx = 12       # home team score index\n",
        "                h_shon_idx = 32     # home shots on target index\n",
        "                h_corn_idx = 20     # home corners index\n",
        "                h_ppg_idx = 10\n",
        "                \n",
        "                away_match_prev = season.loc[(season['away_team_name'] == away_team) & (season['Game Week'] == week-previous)]   # picking out away team's previous match\n",
        "                a_sc_idx = 13       # away team score index\n",
        "                a_shon_idx = 33     # away team shots on target index\n",
        "                a_corn_idx = 21     # away corners index\n",
        "                a_ppg_idx = 11\n",
        "                \n",
        "                # if home team name was not found in 'home_team_name' column...\n",
        "                if (home_match_prev.size == 0):\n",
        "                    home_match_prev = season.loc[(season['away_team_name'] == home_team) & (season['Game Week'] == week-previous)]   # picking out home team's previous match\n",
        "                    h_sc_idx = 13      # home team score index\n",
        "                    h_shon_idx = 33    # home shots on target index\n",
        "                    h_corn_idx = 21    # home corners index\n",
        "                    h_ppg_idx = 11\n",
        "                    \n",
        "                # if away team name was not found in 'away_team_name' column...\n",
        "                if (away_match_prev.size == 0):\n",
        "                    away_match_prev = season.loc[(season['home_team_name'] == away_team) & (season['Game Week'] == week-previous)]   # picking out away team's previous match\n",
        "                    a_sc_idx = 12      # away team score index\n",
        "                    a_shon_idx = 32    # away team shots on target index\n",
        "                    a_corn_idx = 20    # away corners index\n",
        "                    a_ppg_idx = 10\n",
        "                    \n",
        "                # if loop is 1 match in the past...   \n",
        "                if previous == 1:\n",
        "                    home_PPG = home_match_prev.iat[0,h_ppg_idx]\n",
        "                    away_PPG = away_match_prev.iat[0,a_ppg_idx]\n",
        "                    \n",
        "                #print(home_team, 'goals scored in week', week-previous, '= ', home_match_prev.iat[0,h_sc_idx])\n",
        "                total_home_goals += home_match_prev.iat[0,h_sc_idx]\n",
        "                total_away_goals += away_match_prev.iat[0,a_sc_idx]\n",
        "                \n",
        "                #print(home_team, 'goals conceded in week', week-previous, '=', home_match_prev.iat[0,a_sc_idx])\n",
        "                total_home_conceded += home_match_prev.iat[0,a_sc_idx]\n",
        "                total_away_conceded += away_match_prev.iat[0,h_sc_idx]\n",
        "                \n",
        "                total_home_shotson += home_match_prev.iat[0,h_shon_idx]\n",
        "                total_away_shotson += away_match_prev.iat[0,a_shon_idx]\n",
        "                \n",
        "                total_home_corners += home_match_prev.iat[0,h_corn_idx]\n",
        "                total_away_corners += away_match_prev.iat[0,a_corn_idx]\n",
        "                \n",
        "                \n",
        "                previous += 1\n",
        "\n",
        "            in_idx = row_idx - (past*10)\n",
        "            input_season[in_idx][0] = total_home_goals/past          # input INDEX 0 (home team avg. goals over \"past\")\n",
        "            input_season[in_idx][1] = total_home_conceded/past       # input INDEX 1 (home team avg. conceded goals over \"past\")\n",
        "            input_season[in_idx][2] = home_PPG_pre                   # input INDEX 2 (home team pre-match PPG: PPG in current season)\n",
        "            input_season[in_idx][3] = home_PPG                       # input INDEX 3 (home team PPG including past seasons)\n",
        "            input_season[in_idx][4] = total_home_shotson/past        # input INDEX 4 (home team avg. shots on target over \"past\")\n",
        "            input_season[in_idx][5] = total_home_corners/past        # input INDEX 5 (home team avg. corner kicks over \"past\")\n",
        "            input_season[in_idx][6] = total_away_goals/past          # input INDEX 6 (away team avg. goals over \"past\")\n",
        "            input_season[in_idx][7] = total_away_conceded/past       # input INDEX 7 (away team avg. conceded goals over \"past\")\n",
        "            input_season[in_idx][8] = away_PPG_pre                   # input INDEX 8 (away team pre-match PPG: PPG in current season)\n",
        "            input_season[in_idx][9] = away_PPG                       # input INDEX 9 (away team PPG including past seasons)\n",
        "            input_season[in_idx][10] = total_away_shotson/past       # input INDEX 10 (away team avg. shots on target over \"past\")\n",
        "            input_season[in_idx][11] = total_away_corners/past       # input INDEX 11 (away team avg. corner kicks over \"past\")\n",
        "            input_season[in_idx][12] = result                        # label INDEX 12 (match result)\n",
        "            \n",
        "            #print(input_season[in_idx])\n",
        "            \n",
        "            row_idx += 1\n",
        "            match_count += 1\n",
        "\n",
        "        week += 1\n",
        "        \n",
        "    season_idx += 1\n",
        "      \n",
        "        \n",
        "print('19/20 season input matrix: \\n', in_20, '\\n')\n",
        "print('18/19 season input matrix: \\n', in_19, '\\n')\n",
        "print('17/18 season input matrix: \\n', in_18, '\\n')\n",
        "print('16/17 season input matrix: \\n', in_17, '\\n')\n",
        "print('15/16 season input matrix: \\n', in_16, '\\n')\n",
        "print('14/15 season input matrix: \\n', in_15, '\\n')\n",
        "print('13/14 season input matrix: \\n', in_14, '\\n')\n",
        "print('12/13 season input matrix: \\n', in_13, '\\n')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/20 season input matrix: \n",
            " [[1.   1.2  0.5  ... 5.2  4.8  1.  ]\n",
            " [1.2  0.8  2.   ... 6.4  6.4  0.  ]\n",
            " [1.2  1.4  1.5  ... 6.   3.   0.  ]\n",
            " ...\n",
            " [0.8  1.4  1.44 ... 8.   9.4  1.  ]\n",
            " [1.4  0.8  1.   ... 3.8  6.2  0.  ]\n",
            " [2.   0.8  1.17 ... 5.   5.2  2.  ]] \n",
            "\n",
            "18/19 season input matrix: \n",
            " [[ 1.4   2.    1.5  ...  5.8   5.    2.  ]\n",
            " [ 0.6   2.    0.   ...  5.    5.4   0.  ]\n",
            " [ 0.6   1.2   0.5  ... 10.2   8.4   1.  ]\n",
            " ...\n",
            " [ 1.6   2.2   1.22 ...  3.4   3.8   2.  ]\n",
            " [ 1.    0.8   2.06 ...  5.8   8.    2.  ]\n",
            " [ 1.4   1.6   1.5  ...  5.6   6.    1.  ]] \n",
            "\n",
            "17/18 season input matrix: \n",
            " [[0.8  1.2  3.   ... 7.8  9.   1.  ]\n",
            " [1.2  1.   1.5  ... 5.2  6.4  2.  ]\n",
            " [0.4  2.   1.5  ... 3.6  4.2  0.  ]\n",
            " ...\n",
            " [0.4  1.8  1.17 ... 4.4  2.6  1.  ]\n",
            " [1.2  1.2  2.22 ... 3.2  7.2  0.  ]\n",
            " [1.2  2.   1.33 ... 3.6  3.2  0.  ]] \n",
            "\n",
            "16/17 season input matrix: \n",
            " [[1.6  2.   1.5  ... 5.2  4.6  0.  ]\n",
            " [0.6  1.2  1.5  ... 7.8  5.8  0.  ]\n",
            " [2.2  1.2  3.   ... 3.4  4.   0.  ]\n",
            " ...\n",
            " [0.8  0.6  1.33 ... 5.   5.2  1.  ]\n",
            " [1.2  0.4  1.33 ... 3.8  4.6  0.  ]\n",
            " [0.2  1.4  1.56 ... 9.6  8.8  1.  ]] \n",
            "\n",
            "15/16 season input matrix: \n",
            " [[ 1.4   1.8   0.5  ... 10.4   8.    0.  ]\n",
            " [ 1.4   1.    3.   ...  5.2   6.8   2.  ]\n",
            " [ 0.6   1.2   0.   ...  4.    4.    2.  ]\n",
            " ...\n",
            " [ 1.4   1.    1.39 ...  4.4   6.4   0.  ]\n",
            " [ 0.6   3.    1.39 ...  3.8   7.4   0.  ]\n",
            " [ 1.    1.    2.11 ...  4.4   6.6   0.  ]] \n",
            "\n",
            "14/15 season input matrix: \n",
            " [[1.4  1.6  1.5  ... 3.8  5.   2.  ]\n",
            " [3.2  2.2  3.   ... 1.8  5.8  0.  ]\n",
            " [1.6  2.   0.5  ... 2.4  4.   0.  ]\n",
            " ...\n",
            " [3.2  1.2  2.33 ... 3.4  5.6  0.  ]\n",
            " [1.   2.4  1.28 ... 4.4  7.   0.  ]\n",
            " [1.2  0.8  1.67 ... 6.6  5.6  0.  ]] \n",
            "\n",
            "13/14 season input matrix: \n",
            " [[1.   0.2  3.   ... 5.2  5.4  2.  ]\n",
            " [1.2  1.2  0.   ... 4.8  7.   0.  ]\n",
            " [0.6  1.2  0.5  ... 2.2  2.8  1.  ]\n",
            " ...\n",
            " [1.6  1.4  1.   ... 4.4  5.4  1.  ]\n",
            " [2.4  2.8  1.83 ... 4.6  5.   0.  ]\n",
            " [1.2  1.4  1.17 ... 4.4  4.2  1.  ]] \n",
            "\n",
            "12/13 season input matrix: \n",
            " [[1.8  0.4  2.   ... 8.6  4.2  1.  ]\n",
            " [1.8  1.   2.   ... 6.6  4.2  0.  ]\n",
            " [2.4  2.2  3.   ... 9.2  6.6  1.  ]\n",
            " ...\n",
            " [1.2  2.   1.67 ... 6.6  4.6  2.  ]\n",
            " [0.8  1.   1.67 ... 7.2  5.6  0.  ]\n",
            " [1.6  2.2  0.94 ... 8.   5.2  2.  ]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNmJ7F2e0c8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18fe3cc9-2615-4d29-c750-91a3a0905779"
      },
      "source": [
        "# Joining all season input data into one dataset\n",
        "data_full_np = np.concatenate((in_20, in_19, in_18, in_17, in_16, in_15, in_14, in_13), axis=0)\n",
        "\n",
        "# Turn numpy array back into pd.DataFrame\n",
        "columns = ['h_goals','h_conceded','h_prePPG','h_avgPPG','h_shotsOn','h_corners',\n",
        "           'a_goals','a_conceded','a_prePPG','a_avgPPG','a_shotsOn','a_corners',\n",
        "           'outcome']\n",
        "\n",
        "data_full = pd.DataFrame(data_full_np, columns=columns)\n",
        "\n",
        "#Print 'outcome' column sums to determine dataset balance\n",
        "print('The numbers of match outcomes (Home Team Wins, Away Team Wins, Draws):', data_full[\"outcome\"].value_counts())\n",
        "\n",
        "#============================ BALANCE THE DATASET ==========================#\n",
        "#since away wins and ties are roughly the same->want to remove some samples from the over represented class\n",
        "#home wins count =away win count\n",
        "\n",
        "data_full_home  = data_full[data_full[\"outcome\"]==0.0]\n",
        "data_full_away = data_full[data_full[\"outcome\"]==1.0]\n",
        "data_full_tie = data_full[data_full[\"outcome\"]==2.0]\n",
        "# print(data_full_home[\"outcome\"].value_counts(),'\\n')\n",
        "# print(data_full_away[\"outcome\"].value_counts(),'\\n')\n",
        "# print(data_full_tie[\"outcome\"].value_counts(),'\\n')\n",
        "\n",
        "data_full_home = data_full_home.sample(len(data_full_away), random_state=0)\n",
        "# print(data_full_home[\"outcome\"].value_counts(),'\\n')\n",
        "# print(data_full_away[\"outcome\"].value_counts(),'\\n')\n",
        "# print(data_full_tie[\"outcome\"].value_counts(),'\\n')\n",
        "\n",
        "subsets = [data_full_home,data_full_away,data_full_tie]\n",
        "data_full = pd.concat(subsets)\n",
        "print(data_full[\"outcome\"].value_counts(),'\\n')\n",
        "\n",
        "# Get a better idea of what our data looks like BEFORE NORMALIZATION\n",
        "def verbose_print(data):     # helper function\n",
        "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "        print(data.head())\n",
        "       \n",
        "# print(\"\\n \\n Data characteristics:\")\n",
        "# verbose_print(data_full.describe())\n",
        "\n",
        "# Turn 'outcome' column values into one hot-encoded form\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(data_full_np[:,12])   # y is vector of 1-hot encoded labels\n",
        "\n",
        "#X = data_full_np[:,:12]                    # x is matrix of inputs (need to be normalized still)\n",
        "\n",
        "# Normalize continuous inputs\n",
        "X = data_full.drop(columns=['outcome'])\n",
        "\n",
        "for feature in X:\n",
        "  mean = X[feature].mean()\n",
        "  std = X[feature].std()\n",
        "  X[feature] = X[feature] - mean\n",
        "  X[feature] = X[feature]/std\n",
        "\n",
        "X = X.values\n",
        "X = train_test_split(X,test_size=0.2,random_state=1)\n",
        "y = train_test_split(y,test_size=0.2,random_state=1)\n",
        "\n",
        "X_train = X[0]  # extracting training inputs\n",
        "y_train = y[0]  # extracting training labels\n",
        "X_infer = train_test_split(X[1],test_size = 0.33,random_state=1) # splitting inputs into validation and test sets\n",
        "y_infer = train_test_split(y[1],test_size = 0.33,random_state=1) # splitting labels into validation and test sets"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The numbers of match outcomes (Home Team Wins, Away Team Wins, Draws): 0.0    1228\n",
            "1.0     788\n",
            "2.0     624\n",
            "Name: outcome, dtype: int64\n",
            "1.0    788\n",
            "0.0    788\n",
            "2.0    624\n",
            "Name: outcome, dtype: int64 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_QroHKoW2sd"
      },
      "source": [
        "## Multi-Layer Perceptron Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEdgVrZRW2sd"
      },
      "source": [
        "class MultiLayerPerceptron(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size,h_sizes,act):\n",
        "      #current parameters are:\n",
        "        #input size = matrix size\n",
        "        #h_sizes = list of each layer size ->ex: [12,32,32,20,3]\n",
        "        #MAKE SURE LAST HID_LAYER OUTPUTS TO 3\n",
        "        #act_fcn = ?\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "        # self.hidden = nn.ModuleList()\n",
        "        # for k in range(len(h_sizes)-2):\n",
        "        #     self.hidden.append(nn.Linear(h_sizes[k], h_sizes[k+1]))\n",
        "\n",
        "        if act =='relu':\n",
        "          self.act = nn.ReLU()\n",
        "        elif act == 'sigmoid':  \n",
        "          self.act = nn.sigmoid()\n",
        "        self.out = nn.Softmax()\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size,32)\n",
        "        self.fc2 = nn.Linear(32,32)\n",
        "        self.fc3 = nn.Linear(32,20)\n",
        "        self.fc4 = nn.Linear(20,3)   #output is 3 classes for home win, away win, tie\n",
        "\n",
        "    def forward(self, x):\n",
        "      # for i in self.hidden:\n",
        "      #   x = self.act(self.hidden[i])\n",
        "      # x =  self.out(x)\n",
        "\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = F.relu(self.fc3(x))\n",
        "      x = torch.sigmoid(self.fc4(x))\n",
        "      return x"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK461FjGZrXc"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE-dBefR_wCv"
      },
      "source": [
        "#### Dataloader creation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf7SrNHz_xq7"
      },
      "source": [
        "# MatchDataset turns matrix-style datasets into map-style datasets\n",
        "class MatchDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index],self.y[index]\n",
        "    \n",
        "\n",
        "def load_data(batch_size):\n",
        "\n",
        "    train_dataset = MatchDataset(X_train,y_train)\n",
        "    valid_dataset = MatchDataset(X_infer[0],y_infer[0])\n",
        "    test_dataset = MatchDataset(X_infer[1],y_infer[1])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True) \n",
        "\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "train_loader, valid_loader, test_loader = load_data(batch_size)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M0Mu74T_7V0"
      },
      "source": [
        "#### Get prediction from output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnXEA5wlAAUu"
      },
      "source": [
        "def get_preds(z):\n",
        "    \n",
        "  out = np.zeros(z.shape)\n",
        "  #inputs: output of model\n",
        "  #outputs: corresponding output to prediction\n",
        "  max_idxs = torch.max(z,1)[1]\n",
        "  for entry,idx in enumerate(max_idxs,0):\n",
        "      for val in range(3):\n",
        "        if val == idx:\n",
        "          out[entry][val] = 1\n",
        "\n",
        "  return out"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErVMQAJVfGi6"
      },
      "source": [
        "#### Accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GGnhmzFZzpc"
      },
      "source": [
        "def accuracy(preds, labels):\n",
        "    #inputs: preds: array, labels:array \n",
        "    #output: overall accuracy\n",
        "    \n",
        "    correct = 0\n",
        "    for batch in range(len(preds)):\n",
        "        for i in range(3):\n",
        "            if (preds[batch][i] == 1) and (labels[batch][i] == 1):\n",
        "                correct += 1     \n",
        "    #for i in range(len(preds)):\n",
        "     #   if preds[i] == labels[i].numpy():\n",
        "        #  correct +=1\n",
        "    return (correct/len(preds))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJlCum_EBNLh"
      },
      "source": [
        "#### Validate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8PwjiNodBWz"
      },
      "source": [
        "def validate(model,val_loader,loss_fcn):\n",
        "  val_acc=[]\n",
        "  val_loss=[]\n",
        "  for epoch in range(0,num_epochs):\n",
        "    for i,data in enumerate(val_loader,0): #iterate over val_loader, start idx=0\n",
        "      inputs,labels = data\n",
        "\n",
        "      z = model(inputs.float())  #z is size=3 \n",
        "\n",
        "      preds = get_preds(z) #preds used for accuracy \n",
        "\n",
        "      loss = loss_fcn(input=z, target=labels.float())\n",
        "\n",
        "      val_acc.append(accuracy(preds,labels))\n",
        "      val_loss.append(loss.item())\n",
        "\n",
        "  ValLoss = sum(val_loss)/len(val_loss)\n",
        "  ValAcc = sum(val_acc) / len(val_acc)\n",
        "  \n",
        "  return ValAcc, ValLoss"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbQCrISXWN46"
      },
      "source": [
        "#### plotting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd9apCNOWOHQ"
      },
      "source": [
        "def plot(epoch, train_var, val_var,xlabel,ylabel):\n",
        "    plt.plot(epoch, train_var, label = 'train')\n",
        "    plt.plot(epoch, val_var, label = 'validation')\n",
        "    plt.title(str(xlabel) + ' vs. '+str(ylabel))\n",
        "    plt.xlabel(str(xlabel))\n",
        "    plt.ylabel(str(ylabel))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kAaa_MEjVrw"
      },
      "source": [
        "#### MLP loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3vF0n-IjUwj"
      },
      "source": [
        "def load_MLP(lr):\n",
        "  #add optimizer,loss functions as a hyperparameters\n",
        "  model = MultiLayerPerceptron(input_size,h_sizes,act)\n",
        "  optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
        "  loss_fcn = nn.MSELoss()\n",
        "  return model,optimizer,loss_fcn"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfaT7X6ZiWn_"
      },
      "source": [
        "##Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18YWlXsYim9y"
      },
      "source": [
        "def train(rseed,lr,num_epochs):\n",
        "\n",
        "    torch.manual_seed(rseed)\n",
        "\n",
        "    model,optimizer,loss_fcn = load_MLP(lr)   #initialize model\n",
        "\n",
        "    #records for plotting \n",
        "    TrainAccRec = []\n",
        "    TrainLossRec = []\n",
        "    ValAccRec = []  \n",
        "    ValLossRec = []\n",
        " \n",
        "# ========================================TRAINING LOOP =========================================# \n",
        "    for epoch in range(0,num_epochs):\n",
        "        batch_count = 0\n",
        "        train_acc_sum = 0\n",
        "        train_loss_sum = 0\n",
        "        for i,data in enumerate(train_loader,0): #iterate over train_loader, start idx=0\n",
        "            inputs,labels = data\n",
        "\n",
        "            optimizer.zero_grad()  #initialize the gradients to zero  \n",
        "\n",
        "            z = model(inputs.float())  #z is size=3 \n",
        "\n",
        "            preds = get_preds(z) #preds used for accuracy \n",
        "            print(preds)\n",
        "\n",
        "            loss = loss_fcn(input=z, target=labels.float())\n",
        "\n",
        "            loss.backward() #get gradients \n",
        "\n",
        "            optimizer.step() #update parameters\n",
        "\n",
        "            train_acc = accuracy(preds,labels)\n",
        "            train_loss = loss.item()\n",
        "\n",
        "            #add to overall records\n",
        "            train_acc_sum += train_acc\n",
        "            train_loss_sum += train_loss\n",
        "            \n",
        "            batch_count += 1\n",
        "    \n",
        "\n",
        "        TrainAccRec.append(train_acc_sum/batch_count)\n",
        "        TrainLossRec.append(train_loss/batch_count)\n",
        "        val_acc, val_loss = validate(model, valid_loader,loss_fcn)\n",
        "        ValAccRec.append(val_acc)\n",
        "        ValLossRec.append(val_loss)\n",
        "\n",
        "        print(\"Epoch:\",epoch+1)\n",
        "        print(\"train acc:\",train_acc)\n",
        "        print(\"val acc:\",val_acc)\n",
        "\n",
        "    \n",
        "\n",
        "    #plottting\n",
        "    e = np.arange(0,num_epochs)\n",
        "    plot(e,TrainAccRec,ValAccRec,'Epochs','Accuracy')\n",
        "    plot(e,TrainLossRec,ValLossRec,'Epochs','Losses')\n",
        "    print(\"Max training accuracy\",max(TrainAccRec))\n",
        "    print(\"Max Validation accuracy\",max(ValAccRec))\n",
        "    print(\"Min training loss\",min(TrainLossRec))\n",
        "    print(\"Min Validation loss\",min(ValLossRec))\n",
        "\n",
        "\n",
        "train(rseed,lr,num_epochs)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rspi5_SPkw-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scyQEvnePkw-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}